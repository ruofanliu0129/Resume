---
title: "RUOFAN LIU - About Me"
description: "Self Introduction by RUOFAN LIU."
permalink: /
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Ph.D. 3rd year student (2023.10~) at the [Deparment of Computer Science](https://educ.titech.ac.jp/cs/eng/), [Institute of Science Tokyo](https://www.isct.ac.jp/en), supervised by Prof. [Hideki Koike](https://scholar.google.com/citations?hl=en&user=Ih8cJXQAAAAJ).
I am currently a visiting researcher at [Stanford Computational Imaging Lab](https://www.computationalimaging.org/), [Stanford University](https://www.stanford.edu/), supervised by Prof. [Gordon Wetzstein](https://scholar.google.com/citations?user=VOf45S0AAAAJ&hl=en), and a research assistant at [Sony Computer Science Laboratories](https://www.sonycsl.co.jp/), supervised by Prof. [Shinichi Furuya](https://scholar.google.com/citations?hl=en&user=IphDyJcAAAAJ).

I obtained my M.E. in Computer Science at the Institute of Science Tokyo with Prof. Hideki Koike, and obtained my B.E. in Computer Science and Technology at Shanghai Jiao Tong University with Prof. [Baoliang Lu](https://scholar.google.com/citations?hl=en&user=709il6EAAAAJ). 

My research lies at the intersection of <strong>computer vision, multimodal generation for content creation, foundation models, and interactive systems</strong>. My ultimate research goal is to create a next-generation deep learning framework that incorporates cross-modal synthesis and large-scale learning methods. I believe that the critical path toward achieving this involves developing large-scale learning methods that are both more generalizable and explainable. To this end, I have been focusing on the following topics:

<ul>
  <li><strong>Generative AI</strong></li>
  <li><strong>Cross-modal Synthesis/Computation Sensing</strong>: Multimodal learning for pose-to-EMG estimation [NeurIPS '25](https://openreview.net/pdf/26eb537804fde5b11e5fcc37068d9f9fb6ad6fad.pdf), </li>
</ul>

My recent work focuses on using AI technologies to augment humans and investigates the downstream applications in embodied intelligence and skill training. By integrating visual, motor, and physiological signals such as electromyography (EMG), I aim to develop <strong><u>computational frameworks that bridge human perception, physical behavior, and interactive systems</u></strong>. My broader goal is to design intelligent tutoring systems that can perceive, model, and support human expertise in a natural and interpretable way.

Research Interests
------
Video Generation, Multimodal Learning, Mixed Reality, Human-Computer Interaction, Human Augmentation

For more info
------
More info about me can be found in my [CV](https://ruofanliu0129.github.io/Resume/cv/). Please feel free to contact me in English, Chinese, or Japanese.
